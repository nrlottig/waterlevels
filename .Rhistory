print(out, dig = 3)
which(out$BUGSoutput$summary[, c("Rhat")] > 1.1)
# Run the model
out = jags.parallel(data, inits, parameters, "model.txt", n.chains = 3,
n.thin = 60, n.iter = 20000, n.burnin = 10000)
saveRDS(out,"GW_Models/HLM.rds")
# Show some of the result
print(out, dig = 3)
which(out$BUGSoutput$summary[, c("Rhat")] > 1.1)
max(out$BUGSoutput$summary[, c("Rhat")])
20000-10000
10000/500
30000/500
str(out)
501*60
(nt <- ceiling((ni-nb)*nc/500))
(nt <- ceiling((ni-nb)*nc/1500))
# MCMC settings
ni <- 50000
(nt <- ceiling((ni-nb)*nc/1500))
# MCMC settings
ni <- 40000
(nt <- ceiling((ni-nb)*nc/1500))
# Run the model
out = jags.parallel(data, inits, parameters, "model.txt", n.chains = 3,
n.thin = 60, n.iter = 20000, n.burnin = 10000)
# Run the model
out = jags.parallel(data, inits, parameters, "model.txt", n.chains = 3,
n.thin = 60, n.iter = 40000, n.burnin = 10000)
saveRDS(out,"GW_Models/HLM.rds")
# Show some of the result
print(out, dig = 3)
which(out$BUGSoutput$summary[, c("Rhat")] > 1.1)
max(out$BUGSoutput$summary[, c("Rhat")])
out.mcmc <- as.mcmc(out)
str(out.mcmc)
#### Just make plots for parameters of interest
out.mcmc2 <- out.mcmc[,c("mu.alpha","mu.beta")]
xyplot(out.mcmc2)
densityplot(out.mcmc2)
reg.coef = out$BUGSoutput$mean$BB
lakes = unique(dat$WiscID)
pdf("myOutGW.pdf",width=8,height=10.5,onefile = TRUE)
par(mfrow=c(3,2))
for (i in 1:length(lakes)){
#pull out data for each lake and generate predicted water levels
dat.t = dat %>% filter(BHMID==i)
#plot relationship between precip and water level
plot(x = dat.t$PE_mmd, y = dat.t$deltaS_mmd,xlab="Precip - Evap (mm/d)",
ylab="Delta Water Level (mm/d)",pch=16,ylim=range(dat$deltaS_mmd),
xlim=range(dat$PE_mmd))
tryCatch({
abline(lm(dat.t$deltaS_mmd~dat.t$PE_mmd),col="lightblue",lwd=2)
},error=function(e){})
abline(a = reg.coef[i,1][[1]],b=reg.coef[i,2][[1]],col="red",lwd=2)
abline(a = out$BUGSoutput$mean$mu.alpha,b=out$BUGSoutput$mean$mu.beta,col="green",lwd=2)
mtext(side=1,adj=0.9,line=-2,round(reg.coef[i,1][[1]],3))
mtext(side=3,line=1,paste(dat.t$SiteName[1], " WiscID:",dat.t$WiscID[1],sep=""),cex=.8)
legend('topleft',legend=c("linear","bayesH","global"),lty=1,col=c("lightblue","red","green"))
}
dev.off()
write_csv(data.frame(WiscID=lakes,Gnet=reg.coef[,1],slope=reg.coef[,2]),"GW_Models/HLM_out.csv")
# Input data
dt = read_csv("GW_Models/lake_climate_20180414_openWaterSeason.csv")
dat = dt %>% select(WiscID,Date1,DeltaDate,Stage1_mm,Stage2_mm,DeltaWaterLevel_mm,
Precip_mm,Evap_mm) %>% drop_na() %>% arrange(WiscID,Date1) %>%
mutate(PE_mmd = (Precip_mm+Evap_mm)/DeltaDate) %>%
mutate(deltaS_mmd=DeltaWaterLevel_mm/DeltaDate)
#Filter the data so that we have at least 5 obs for each lake
num.rec = table(dat$WiscID)
keep.rec = as.numeric(names((num.rec[which(num.rec>=10)])))
dat = dat[which(dat$WiscID %in% keep.rec),]
summary(dat)
####Look at the data
str(dat)
length(unique(dat$WiscID))
dt = read_csv("GW_Models/lake_climate_20180414_openWaterSeason.csv")
dat = dt %>% select(WiscID,Date1,DeltaDate,Stage1_mm,Stage2_mm,DeltaWaterLevel_mm,
Precip_mm,Evap_mm) %>% drop_na() %>% arrange(WiscID,Date1) %>%
mutate(PE_mmd = (Precip_mm+Evap_mm)/DeltaDate) %>%
mutate(deltaS_mmd=DeltaWaterLevel_mm/DeltaDate)
#Filter the data so that we have at least 5 obs for each lake
num.rec = table(dat$WiscID)
keep.rec = as.numeric(names((num.rec[which(num.rec>=8)])))
dat = dat[which(dat$WiscID %in% keep.rec),]
length(unique(dat$WiscID))
dt = read_csv("GW_Models/lake_climate_20180414_openWaterSeason.csv")
dat = dt %>% select(WiscID,Date1,DeltaDate,Stage1_mm,Stage2_mm,DeltaWaterLevel_mm,
Precip_mm,Evap_mm) %>% drop_na() %>% arrange(WiscID,Date1) %>%
mutate(PE_mmd = (Precip_mm+Evap_mm)/DeltaDate) %>%
mutate(deltaS_mmd=DeltaWaterLevel_mm/DeltaDate)
#Filter the data so that we have at least 5 obs for each lake
num.rec = table(dat$WiscID)
keep.rec = as.numeric(names((num.rec[which(num.rec>=5)])))
dat = dat[which(dat$WiscID %in% keep.rec),]
length(unique(dat$WiscID))
allLakeList = unique(dat$WiscID)
dat$BHMID = NA
for (i in 1:length(allLakeList)) {
dat$BHMID[dat$WiscID %in% allLakeList[i]] = i
}
# The Model
sink("model.txt")
cat("
model {
# Likelihood:
# Level-1 of the model
for (i in 1:n){
y[i] ~ dt(mu[i], tau, tdf)
mu[i] <- alpha[group[i]] + beta[group[i]] * precip[i]
}
# Level-2 of the model
for(j in 1:J){
alpha[j] <- BB[j,1]
beta[j] <- BB[j,2]
BB[j,1:K] ~ dmnorm(BB.hat[j,], Tau.B[,]) # bivriate normal
BB.hat[j,1] <- mu.alpha
BB.hat[j,2] <- mu.beta
}
# Priors and derived quantities
sigma ~ dunif(0, 100)
tau <- pow(sigma,-2) # precision
udf ~ dunif(0,1)
tdf <- 1 - tdfGain *log(1-udf)
sigma2 <- pow(sigma,2)
mu.alpha ~ dnorm(0, 0.0001)
mu.beta ~ dnorm(0, 0.0001)
# Convert covariance matrix to precision for use in bivariate normal above
Tau.B[1:K,1:K] <- inverse(Sigma.B[,])
# variance among intercepts
Sigma.B[1,1] <- pow(sigma.a, 2)
sigma.a ~ dunif (0, 100)
# Variance among slopes
Sigma.B[2,2] <- pow(sigma.b, 2)
sigma.b ~ dunif (0, 100)
# Covariance between alpha's and beta's
Sigma.B[1,2] <- rho * sigma.a * sigma.b
Sigma.B[2,1] <- Sigma.B[1,2]
# Uniform prior on correlation
rho ~ dunif (-1, 1)
} # end model
",fill = TRUE)
sink()
# Set up the parameters before run the model
# Number of parameters
K = 2
# Number of lakes
J = length(unique(dat$BHMID))
# Load data raw water level data
tdfGain = 1
dat = as.data.frame(dat)
data = list(y = dat$deltaS_mmd, group = as.numeric(dat$BHMID), n = dim(dat)[1], J = J,
precip = dat$PE_mmd, K = K,tdfGain = tdfGain)
# Initial values
inits = function (){
list(mu.alpha = rnorm(1), mu.beta=rnorm(1), sigma=runif(1),
BB=matrix(rnorm(J*K),nrow=J,ncol=K), sigma.a=runif(1), sigma.b=runif(1), rho=runif(1),
udf = 0.95)
}
# Parameters monitored
# mu.alpha: global alpha
# mu.beta: global beta
# BB: local alphas and betas
# sigma: local error term
# sigma.a: variances of alpha
# sigma.b: variances of beta
# rho: covarainces of alpha and beta
#
parameters = c("mu.alpha","mu.beta","BB","sigma", "sigma.a", "sigma.b","rho")
# MCMC settings
ni <- 40000
nb <- 10000
nc <- 3
(nt <- ceiling((ni-nb)*nc/1500))
# Run the model
out = jags.parallel(data, inits, parameters, "model.txt", n.chains = 3,
n.thin = 60, n.iter = 40000, n.burnin = 10000)
saveRDS(out,"GW_Models/HLM_reduced.rds")
# Show some of the result
print(out, dig = 3)
which(out$BUGSoutput$summary[, c("Rhat")] > 1.1)
max(out$BUGSoutput$summary[, c("Rhat")])
out.mcmc <- as.mcmc(out)
#### Just make plots for parameters of interest
out.mcmc2 <- out.mcmc[,c("mu.alpha","mu.beta")]
xyplot(out.mcmc2)
densityplot(out.mcmc2)
xyplot(out.mcmc2)
reg.coef = out$BUGSoutput$mean$BB
lakes = unique(dat$WiscID)
pdf("myOutGW.pdf",width=8,height=10.5,onefile = TRUE)
par(mfrow=c(3,2))
for (i in 1:length(lakes)){
#pull out data for each lake and generate predicted water levels
dat.t = dat %>% filter(BHMID==i)
#plot relationship between precip and water level
plot(x = dat.t$PE_mmd, y = dat.t$deltaS_mmd,xlab="Precip - Evap (mm/d)",
ylab="Delta Water Level (mm/d)",pch=16,ylim=range(dat$deltaS_mmd),
xlim=range(dat$PE_mmd))
tryCatch({
abline(lm(dat.t$deltaS_mmd~dat.t$PE_mmd),col="lightblue",lwd=2)
},error=function(e){})
abline(a = reg.coef[i,1][[1]],b=reg.coef[i,2][[1]],col="red",lwd=2)
abline(a = out$BUGSoutput$mean$mu.alpha,b=out$BUGSoutput$mean$mu.beta,col="green",lwd=2)
mtext(side=1,adj=0.9,line=-2,round(reg.coef[i,1][[1]],3))
mtext(side=3,line=1,paste(dat.t$SiteName[1], " WiscID:",dat.t$WiscID[1],sep=""),cex=.8)
legend('topleft',legend=c("linear","bayesH","global"),lty=1,col=c("lightblue","red","green"))
}
dev.off()
write_csv(data.frame(WiscID=lakes,Gnet=reg.coef[,1],slope=reg.coef[,2]),"GW_Models/HLM_out.csv")
dt = read_csv("GW_Models/lake_climate_20180414_openWaterSeason.csv")
dat = dt %>% select(WiscID,Date1,DeltaDate,Stage1_mm,Stage2_mm,DeltaWaterLevel_mm,
Precip_mm,Evap_mm) %>% drop_na() %>% arrange(WiscID,Date1) %>%
mutate(PE_mmd = (Precip_mm+Evap_mm)/DeltaDate) %>%
mutate(deltaS_mmd=DeltaWaterLevel_mm/DeltaDate)
#Filter the data so that we have at least 5 obs for each lake
num.rec = table(dat$WiscID)
keep.rec = as.numeric(names((num.rec[which(num.rec>=10)])))
dat = dat[which(dat$WiscID %in% keep.rec),]
length(unique(dat$WiscID))
str(dat)
summary(dat)
# Reassign a WiscID to all lakes
# This is not the WiscID used in the big dataset!!!
# Because the jags methods requires a consecutive ID list starting from 1
allLakeList = unique(dat$WiscID)
dat$BHMID = NA
for (i in 1:length(allLakeList)) {
dat$BHMID[dat$WiscID %in% allLakeList[i]] = i
}
# The Model
sink("model.txt")
cat("
model {
# Likelihood:
# Level-1 of the model
for (i in 1:n){
y[i] ~ dt(mu[i], tau, tdf)
mu[i] <- alpha[group[i]] + beta[group[i]] * precip[i]
}
# Level-2 of the model
for(j in 1:J){
alpha[j] <- BB[j,1]
beta[j] <- BB[j,2]
BB[j,1:K] ~ dmnorm(BB.hat[j,], Tau.B[,]) # bivriate normal
BB.hat[j,1] <- mu.alpha
BB.hat[j,2] <- mu.beta
}
# Priors and derived quantities
sigma ~ dunif(0, 100)
tau <- pow(sigma,-2) # precision
udf ~ dunif(0,1)
tdf <- 1 - tdfGain *log(1-udf)
sigma2 <- pow(sigma,2)
mu.alpha ~ dnorm(0, 0.0001)
mu.beta ~ dnorm(0, 0.0001)
# Convert covariance matrix to precision for use in bivariate normal above
Tau.B[1:K,1:K] <- inverse(Sigma.B[,])
# variance among intercepts
Sigma.B[1,1] <- pow(sigma.a, 2)
sigma.a ~ dunif (0, 100)
# Variance among slopes
Sigma.B[2,2] <- pow(sigma.b, 2)
sigma.b ~ dunif (0, 100)
# Covariance between alpha's and beta's
Sigma.B[1,2] <- rho * sigma.a * sigma.b
Sigma.B[2,1] <- Sigma.B[1,2]
# Uniform prior on correlation
rho ~ dunif (-1, 1)
} # end model
",fill = TRUE)
sink()
# Set up the parameters before run the model
# Number of parameters
K = 2
# Number of lakes
J = length(unique(dat$BHMID))
# Load data raw water level data
tdfGain = 1
dat = as.data.frame(dat)
data = list(y = dat$deltaS_mmd, group = as.numeric(dat$BHMID), n = dim(dat)[1], J = J,
precip = dat$PE_mmd, K = K,tdfGain = tdfGain)
# Initial values
inits = function (){
list(mu.alpha = rnorm(1), mu.beta=rnorm(1), sigma=runif(1),
BB=matrix(rnorm(J*K),nrow=J,ncol=K), sigma.a=runif(1), sigma.b=runif(1), rho=runif(1),
udf = 0.95)
}
# Parameters monitored
# mu.alpha: global alpha
# mu.beta: global beta
# BB: local alphas and betas
# sigma: local error term
# sigma.a: variances of alpha
# sigma.b: variances of beta
# rho: covarainces of alpha and beta
#
parameters = c("mu.alpha","mu.beta","BB","sigma", "sigma.a", "sigma.b","rho")
# MCMC settings
ni <- 40000
nb <- 10000
nc <- 3
(nt <- ceiling((ni-nb)*nc/1500))
# Run the model
out = jags.parallel(data, inits, parameters, "model.txt", n.chains = 3,
n.thin = 60, n.iter = 40000, n.burnin = 10000)
saveRDS(out,"GW_Models/HLM_reduced.rds")
# Show some of the result
print(out, dig = 3)
which(out$BUGSoutput$summary[, c("Rhat")] > 1.1)
max(out$BUGSoutput$summary[, c("Rhat")])
out.mcmc <- as.mcmc(out)
#### Just make plots for parameters of interest
out.mcmc2 <- out.mcmc[,c("mu.alpha","mu.beta")]
xyplot(out.mcmc2)
# Create traceplots
xyplot(out.mcmc)
# Look at posterior density plots
densityplot(out.mcmc)
par(mfrow=c(4,4))
# Create traceplots
xyplot(out.mcmc)
?xyplot
# Create traceplots
xyplot(out.mcmc,layout =c(4,4))
reg.coef = out$BUGSoutput$mean$BB
lakes = unique(dat$WiscID)
pdf("myOutGW.pdf",width=8,height=10.5,onefile = TRUE)
par(mfrow=c(3,2))
for (i in 1:length(lakes)){
#pull out data for each lake and generate predicted water levels
dat.t = dat %>% filter(BHMID==i)
#plot relationship between precip and water level
plot(x = dat.t$PE_mmd, y = dat.t$deltaS_mmd,xlab="Precip - Evap (mm/d)",
ylab="Delta Water Level (mm/d)",pch=16,ylim=range(dat$deltaS_mmd),
xlim=range(dat$PE_mmd))
tryCatch({
abline(lm(dat.t$deltaS_mmd~dat.t$PE_mmd),col="lightblue",lwd=2)
},error=function(e){})
abline(a = reg.coef[i,1][[1]],b=reg.coef[i,2][[1]],col="red",lwd=2)
abline(a = out$BUGSoutput$mean$mu.alpha,b=out$BUGSoutput$mean$mu.beta,col="green",lwd=2)
mtext(side=1,adj=0.9,line=-2,round(reg.coef[i,1][[1]],3))
mtext(side=3,line=1,paste(dat.t$SiteName[1], " WiscID:",dat.t$WiscID[1],sep=""),cex=.8)
legend('topleft',legend=c("linear","bayesH","global"),lty=1,col=c("lightblue","red","green"))
}
dev.off()
write_csv(data.frame(WiscID=lakes,Gnet=reg.coef[,1],slope=reg.coef[,2]),"GW_Models/HLM_out.csv")
View(reg.coef)
hist(reg.coef)
hist(reg.coef[,1])
summary(reg.coef)
library(tidyverse)
library(randomForest)
library(caret)
library(e1071)
require(VSURF)
library(readxl)
library(LAGOSNE)
EcoContext <- read_excel("RFModels/EcoContext.xlsx")
regressionstats <- read_csv("GW_Models/HLM_out.csv")
lagoscrosswalk <- read_csv("RFModels/lagoscrosswalk.csv")
lagoscrosswalk = lagoscrosswalk %>% select(WiscID,lagoslakeid)
dt <- lagosne_load(version = "1.087.1")
dt.lakes= dt$lakes_limno
dat = regressionstats %>% left_join(lagoscrosswalk) %>% drop_na(lagoslakeid) %>% left_join(select(dt$lakes_limno,lagoslakeid,maxdepth)) %>%
left_join(dt$buffer500m.lulc) %>% select(everything(),-contains("nlcd2001"),-contains("nlcd1992"),-contains("nlcd2006")) %>%
left_join(select(dt$locus,lagoslakeid,lake_area_ha,lake_perim_meters,elevation_m)) %>% drop_na(buffer500m_nhdid) %>%
left_join(select(dt$iws,lagoslakeid,iws_ha)) %>% select(everything(),-contains("nlcd2011_ha"),-buffer500m_nhdid) %>%
mutate(walaratio = iws_ha/lake_area_ha)  %>% left_join(select(EcoContext,WiscID,MaxDepth)) %>% mutate(MaxDepth = MaxDepth*0.3048)
View(dat)
View(regressionstats)
View(dat)
dat$maxdepth[is.na(dat$maxdepth)] = dat$MaxDepth[is.na(dat$maxdepth)]
dat = dat %>% drop_na(maxdepth) %>% filter(maxdepth>0) %>% select(-MaxDepth)
View(dat)
dat = regressionstats %>% left_join(lagoscrosswalk) %>% drop_na(lagoslakeid) %>% left_join(select(dt$lakes_limno,lagoslakeid,maxdepth)) %>%
left_join(dt$buffer500m.lulc) %>% select(everything(),-contains("nlcd2001"),-contains("nlcd1992"),-contains("nlcd2006")) %>%
left_join(select(dt$locus,lagoslakeid,lake_area_ha,lake_perim_meters,elevation_m)) %>% drop_na(buffer500m_nhdid) %>%
left_join(select(dt$iws,lagoslakeid,iws_ha)) %>% select(everything(),-contains("nlcd2011_ha"),-buffer500m_nhdid) %>%
mutate(walaratio = iws_ha/lake_area_ha)  %>% left_join(select(EcoContext,WiscID,MaxDepth)) %>% mutate(MaxDepth = MaxDepth*0.3048)
dat$maxdepth[is.na(dat$maxdepth)] = dat$MaxDepth[is.na(dat$maxdepth)]
dat = dat %>% drop_na(maxdepth) %>% filter(maxdepth>0) %>% select(-MaxDepth)
names(dat)
#set response variable
Y.col = 2
model.data = dat #choose which dataset to use so code works without editing further down
names(model.data)
#set response variable
Y.col = 2
Y = model.data[[Y.col]]
names(model.data)[Y.col]
X = model.data[,c(3,5:43)]
names(X)
names(X)
#,sampsize=rep(min(table(Y)),nlevels(Y)),strata=Y)
(rf.data = randomForest(y = Y,x = X,keep.inbag=TRUE,importance=TRUE,ntree=10001)
#,sampsize=rep(min(table(Y)),nlevels(Y)),strata=Y
(rf.data = randomForest(y = Y,x = X,keep.inbag=TRUE,importance=TRUE,ntree=10001))
pred = predict(rf.data)
plot(Y,pred)
med.vsurf = VSURF(x = X,y = Y,parallel = TRUE,ncores = 7,clusterType = "FORK")
str(med.vsurf)
med.vsurf$varselect.interp
X = model.data[,c(5:43)]
names(X)
#,sampsize=rep(min(table(Y)),nlevels(Y)),strata=Y
(rf.data = randomForest(y = Y,x = X,keep.inbag=TRUE,importance=TRUE,ntree=10001))
names(model.data)
#set response variable
Y.col = 3
Y = model.data[[Y.col]]
names(model.data)[Y.col]
names(model.data)[Y.col]
#,sampsize=rep(min(table(Y)),nlevels(Y)),strata=Y
(rf.data = randomForest(y = Y,x = X,keep.inbag=TRUE,importance=TRUE,ntree=10001))
libdat = EcoContext %>% left_join(regressionstats) %>% select(-ID,-OBJECTID,-WATERBODY_NAME,-HYDROID,-HYDROCODE,
-HYDROTYPE,-LANDLOCK_C,-WBIC,-SHAPE_AREA,-SHAPE_LEN,
-County,-MeanDepth,-problem,-hydro24k,-centroid_x,
-centroid_y,-NATURAL_COMMUNITY,-Lake_type,-HYDROLOGY,
-`Katie classification`,-`Katie notes`) %>% drop_na()
View(libdat)
dat = EcoContext %>% left_join(regressionstats) %>% select(-ID,-OBJECTID,-WATERBODY_NAME,-HYDROID,-HYDROCODE,
-HYDROTYPE,-LANDLOCK_C,-WBIC,-SHAPE_AREA,-SHAPE_LEN,
-County,-MeanDepth,-problem,-hydro24k,-centroid_x,
-centroid_y,-NATURAL_COMMUNITY,-Lake_type,-HYDROLOGY,
-`Katie classification`,-`Katie notes`) %>% drop_na()
dat = dat %>% select(-W_BD_201,-W_BD_204,-W_BD_205,-W_BD_206,-W_BD_207,-W_BD_208,-W_BD_209,-W_BD_210,-W_BD_MISSI,
-W_BR_2,-W_BR_3,-W_BR_MISSI,-W_QG_3,-W_QG_4,-W_QG_6,-W_QG_7,-W_QG_8,-W_QG_9,-W_QG_10,
-W_QG_11,-W_QG_12,-W_QG_13,-W_QG_14,-W_QG_15,-W_QG_16,-W_QG_17,-W_QG_18,-W_QG_20,
-W_QG_21,-W_QG_22,-W_QG_24,-W_QG_29,-W_QG_99,-W_QG_MISSI,-W_LU06_23,-W_LU06_24,-W_LU06_31)
dat = dat %>% select(everything(),-contains("LU11"))
summary(dat)
dat = dat %>% mutate(W_LA_Ratio = WatershedA/Area)
model.data = dat #choose which dataset to use so code works without editing further down
names(model.data)
#set response variable
Y.col = 40
Y = model.data[[Y.col]]
names(model.data)[Y.col]
X = model.data[,c(2:37)]
names(X)
X = model.data[,c(2:37,41)]
names(X)
#,sampsize=rep(min(table(Y)),nlevels(Y)),strata=Y
(rf.data = randomForest(y = Y,x = X,keep.inbag=TRUE,importance=TRUE,ntree=10001))
#set response variable
Y.col = 39
Y = model.data[[Y.col]]
names(model.data)[Y.col]
#,sampsize=rep(min(table(Y)),nlevels(Y)),strata=Y
(rf.data = randomForest(y = Y,x = X,keep.inbag=TRUE,importance=TRUE,ntree=10001))
summary(regressionstats$Gnet)
-1.75*365/10
-1.45*365/10
global.slope = as.numeric(quantile(out$BUGSoutput$sims.list$mu.alpha,c(0.025,0.975)))
sapply(out$BUGSoutput$sims.list$BB[1:4500,1:466,2],function(x) quantile(x,c(0.025,0.975)))
str(out)
global.slope = as.numeric(quantile(out$BUGSoutput$sims.list$mu.beta,c(0.025,0.975)))
sapply(out$BUGSoutput$sims.list$BB[1:1500,1:51,1],function(x) quantile(x,c(0.025,0.975)))
sims.out = as.data.frame(out$BUGSoutput$sims.list$BB[1:1500,1:51,1])
lakeinterval = as.data.frame(t(sapply(sims.out,function(x) quantile(x,c(0.025,0.975)))))
lake.interval = Intervals(t(sapply(sims.out,function(x) quantile(x,c(0.025,0.975)))))
over.lap = interval_overlap(from = lake.interval,to = global.slope)
over.lap = as.numeric(sapply(over.lap,'[',1))
library(intervals)
lake.interval = Intervals(t(sapply(sims.out,function(x) quantile(x,c(0.025,0.975)))))
over.lap = interval_overlap(from = lake.interval,to = global.slope)
over.lap = as.numeric(sapply(over.lap,'[',1))
over.lap
lake.interval
slope.class = rep(NA,51)
for(i in 1:nrow(lakeinterval)){
if (lakeinterval[i,2] < global.slope[1]) slope.class[i] = 0 else if(lakeinterval[i,1] > global.slope[2]) slope.class[i]=2 else slope.class[i] =1
}
slope.class
global.slope
global.slope = as.numeric(quantile(out$BUGSoutput$sims.list$mu.beta,c(0.025,0.975)))
global.slope
out
str(out)
global.slope = as.numeric(quantile(out$BUGSoutput$sims.list$mu.alpha,c(0.025,0.975)))
slope.class = rep(NA,51)
for(i in 1:nrow(lakeinterval)){
if (lakeinterval[i,2] < global.slope[1]) slope.class[i] = 0 else if(lakeinterval[i,1] > global.slope[2]) slope.class[i]=2 else slope.class[i] =1
}
slope.class
table(slope.class)
lake.interval
global.slope
View(regressionstats)
regressionstats$gnet.class = slope.class
View(regressionstats)
install.packages("BayesianFirstAid")
install.packages("BayesianFirstAid")
install.packages("BEST")
library(BEST)
y1 = out$BUGSoutput$sims.list$mu.alpha
y2 =out$BUGSoutput$sims.list$BB[1:1500,7,1]
BESTout = BESTmcmc(y1,y2)
plot(BESTout)
graphics.off()
plot(BESTout)
mean(y1)
mean(y2)
hist(y1-y2)
plot(BESTout)
mean(y1-y2)
y2 =out$BUGSoutput$sims.list$BB[1:1500,1,1]
BESTout = BESTmcmc(y1,y2)
plot(BESTout)
mean(y1-y2)
hist(y1-y2)
